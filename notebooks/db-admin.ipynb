{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234a69db",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6f151",
   "metadata": {},
   "source": [
    "### This notebook demostrates Lake Formation Governed Tables ACID Transactions behavior in below scenarios:\n",
    "  Scenario A: User A makes changes using T1 and commit transaction. User B queries table using T2 and see changes.<br>\n",
    "  Scenario B: User A makes changes using T3 but does not commit transaction. User B queries using T4 and cannot see the changes.<br>\n",
    "  Scenario C: User A commits transaction T3, User B again queries using T4 but still cannot see the changes since T4 started before T3 is committed.<br>\n",
    "  Scenario D: User A make changes to multiple tables using transaction T5, but if writes to one of the tables fail then transaction T5 would aborted and changes performed to none of the tables under T5 would be visible .<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7435e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>12</td><td>application_1631086109765_0013</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-33-184-22.ec2.internal:20888/proxy/application_1631086109765_0013/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-33-165-69.ec2.internal:8042/node/containerlogs/container_1631086109765_0013_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql import DataFrame, Row\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue import DynamicFrame\n",
    "\n",
    "\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "\n",
    "# Please replace below with your parameters\n",
    "bucket_name = \"lf-data-lake-162611428811\"\n",
    "database_name = \"governed_demo\"\n",
    "table_name = \"employee_details\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2012a",
   "metadata": {},
   "source": [
    "### Begin Transaction (txId1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2dcf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e295b03d40c94f2b990685380cc7c1c5"
     ]
    }
   ],
   "source": [
    "txId1 = glueContext.begin_transaction(read_only=False)\n",
    "print(txId1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0567cd3",
   "metadata": {},
   "source": [
    "### Write additional rows and commit transaction (txId1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90744955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+----------+---------+------+\n",
      "|age|  city|employee_id|first_name|last_name|salary|\n",
      "+---+------+-----------+----------+---------+------+\n",
      "| 40|Denver|       1022|     Ellis|      Dow|  4250|\n",
      "| 41|Boston|       1023|    Wesley|   Harris|  4135|\n",
      "+---+------+-----------+----------+---------+------+\n",
      "\n",
      "<awsglue.dynamicframe.DynamicFrame object at 0x7f38de0a45c0>\n",
      "JavaObject id=o110"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "products1 = [\n",
    "    {'employee_id':1022, 'first_name': 'Ellis', 'last_name': 'Dow', 'age':40, 'city':'Denver', 'salary':4250},\n",
    "     {'employee_id':1023, 'first_name': 'Wesley', 'last_name': 'Harris', 'age':41, 'city':'Boston', 'salary':4135}\n",
    "]\n",
    "df1 = spark.createDataFrame(Row(**x) for x in products1)\n",
    "df1.show()\n",
    "\n",
    "dyf1 = DynamicFrame.fromDF(df1, glueContext, \"dyf1\")\n",
    "\n",
    "sink = glueContext.getSink(\n",
    "    connection_type=\"s3\", \n",
    "    path=f\"s3://{bucket_name}/target/{table_name}/\",\n",
    "    enableUpdateCatalog=True, \n",
    "    updateBehavior=\"UPDATE_IN_DATABASE\",\n",
    "    transactionId=txId1\n",
    ")\n",
    "sink.setFormat(\"glueparquet\")\n",
    "sink.setCatalogInfo(catalogDatabase=database_name, catalogTableName=table_name)\n",
    "\n",
    "try:\n",
    "    sink.writeFrame(dyf1)\n",
    "    glueContext.commit_transaction(txId1)\n",
    "except:\n",
    "    glueContext.abort_transaction(txId1)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6e1a5",
   "metadata": {},
   "source": [
    "### Begin Transaction (txId2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2610b343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30d4216cc5364b30819578b40d3fbb6e"
     ]
    }
   ],
   "source": [
    "txId2 = glueContext.begin_transaction(read_only=False)\n",
    "print(txId2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ecc9d0",
   "metadata": {},
   "source": [
    "### Write additional rows but transaction is not committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e269800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+----------+---------+------+\n",
      "|age|  city|employee_id|first_name|last_name|salary|\n",
      "+---+------+-----------+----------+---------+------+\n",
      "| 39|Denver|       1024|     Megan|    Sisco|  4320|\n",
      "| 40|Boston|       1025|     Jenny|   Weaver|  3935|\n",
      "+---+------+-----------+----------+---------+------+\n",
      "\n",
      "<awsglue.dynamicframe.DynamicFrame object at 0x7f38de0a4208>"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "products1 = [\n",
    "    {'employee_id':1024, 'first_name': 'Megan', 'last_name': 'Sisco', 'age':39, 'city':'Denver', 'salary':4320},\n",
    "    {'employee_id':1025, 'first_name': 'Jenny', 'last_name': 'Weaver', 'age':40, 'city':'Boston', 'salary':3935}\n",
    "]\n",
    "df4 = spark.createDataFrame(Row(**x) for x in products1)\n",
    "df4.show()\n",
    "\n",
    "dyf3 = DynamicFrame.fromDF(df4, glueContext, \"df3dyf\")\n",
    "\n",
    "sink = glueContext.getSink(\n",
    "    connection_type=\"s3\", \n",
    "    path=f\"s3://{bucket_name}/target/{table_name}/\",\n",
    "    enableUpdateCatalog=True, \n",
    "    updateBehavior=\"UPDATE_IN_DATABASE\",\n",
    "    transactionId=txId2\n",
    ")\n",
    "sink.setFormat(\"glueparquet\")\n",
    "sink.setCatalogInfo(catalogDatabase=database_name, catalogTableName=table_name)\n",
    "\n",
    "sink.writeFrame(dyf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d8770",
   "metadata": {},
   "source": [
    "### Find employees from Denver using same transaction Id (txId2) used for writing the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164a7f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+---+------+------+\n",
      "|employee_id|first_name|last_name|age|  city|salary|\n",
      "+-----------+----------+---------+---+------+------+\n",
      "|       1013|   William|    Moore| 37|Denver|  3998|\n",
      "|       1018| Frederick|   Wilson| 38|Denver|  4500|\n",
      "|       1022|     Ellis|      Dow| 40|Denver|  4250|\n",
      "|       1024|     Megan|    Sisco| 39|Denver|  4320|\n",
      "+-----------+----------+---------+---+------+------+"
     ]
    }
   ],
   "source": [
    "dyf4 = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database = database_name, \n",
    "    table_name = table_name, \n",
    "    transformation_ctx = \"dyf4\", \n",
    "    additional_options = {\n",
    "        \"transactionId\": txId2\n",
    "    }\n",
    ")\n",
    "df5 = dyf4.toDF()\n",
    "df6 = df5.select('employee_id','first_name','last_name','age','city','salary')\n",
    "df6.where(\"city == 'Denver'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73478eb",
   "metadata": {},
   "source": [
    "### Commit transaction (txId2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1144e16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaObject id=o146"
     ]
    }
   ],
   "source": [
    "glueContext.commit_transaction(txId2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73948e3e",
   "metadata": {},
   "source": [
    "### Working with multiple tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "txId3 = glueContext.begin_transaction(read_only=False)\n",
    "print(txId3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "products1 = [\n",
    "    {'employee_id':1026, 'first_name': 'Dillan', 'last_name': 'Marks', 'age':45, 'city':'Denver', 'salary':4575},\n",
    "    {'employee_id':1027, 'first_name': 'Lucas', 'last_name': 'Wyman', 'age':38, 'city':'Chicago', 'salary':4102}\n",
    "]\n",
    "df4 = spark.createDataFrame(Row(**x) for x in products1)\n",
    "df4.show()\n",
    "\n",
    "dyf3 = DynamicFrame.fromDF(df4, glueContext, \"df3dyf\")\n",
    "\n",
    "sink = glueContext.getSink(\n",
    "    connection_type=\"s3\", \n",
    "    path=f\"s3://{bucket_name}/target/{table_name}/\",\n",
    "    enableUpdateCatalog=True, \n",
    "    updateBehavior=\"UPDATE_IN_DATABASE\",\n",
    "    transactionId=txId3\n",
    ")\n",
    "sink.setFormat(\"glueparquet\")\n",
    "sink.setCatalogInfo(catalogDatabase=database_name, catalogTableName=\"employee_details\")\n",
    "\n",
    "try:\n",
    "    sink.writeFrame(dyf3)\n",
    "except:\n",
    "    glueContext.abort_transaction(txId3)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyf5 = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database = database_name, \n",
    "    table_name = table_name, \n",
    "    transformation_ctx = \"dyf5\", \n",
    "    additional_options = {\n",
    "        \"transactionId\": txId3\n",
    "    }\n",
    ")\n",
    "df7 = dyf5.toDF()\n",
    "df8 = df7.select('employee_id','first_name','last_name','age','city','salary')\n",
    "df8.where(\"city == 'Denver'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "products1 = [\n",
    "    {'employee_id':1026, 'department': 'Finance'},\n",
    "    {'employee_id':1027, 'department': 'IT'}\n",
    "]\n",
    "df5 = spark.createDataFrame(Row(**x) for x in products1)\n",
    "df5.show()\n",
    "\n",
    "dyf4 = DynamicFrame.fromDF(df5, glueContext, \"df3dyf\")\n",
    "\n",
    "sink = glueContext.getSink(\n",
    "    connection_type=\"s3\", \n",
    "    path=f\"s3://{bucket_name}/target/employee_department/\",\n",
    "    enableUpdateCatalog=True, \n",
    "    updateBehavior=\"UPDATE_IN_DATABASE\",\n",
    "    transactionId=txId3\n",
    ")\n",
    "sink.setFormat(\"glueparquet\")\n",
    "sink.setCatalogInfo(catalogDatabase=database_name, catalogTableName=\"employee_department\")\n",
    "\n",
    "try:\n",
    "    sink.writeFrame(dyf4)\n",
    "    glueContext.commit_transaction(txId3)\n",
    "except:\n",
    "    glueContext.abort_transaction(txId3)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "txId4 = glueContext.begin_transaction(read_only=False)\n",
    "\n",
    "dyf6 = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database = database_name, \n",
    "    table_name = \"employee_details\", \n",
    "    transformation_ctx = \"dyf6\", \n",
    "    additional_options = {\n",
    "        \"transactionId\": txId4\n",
    "    }\n",
    ")\n",
    "df9 = dyf6.toDF()\n",
    "df10 = df9.select('employee_id','first_name','last_name','age','city','salary')\n",
    "dfEmp = df9.where(\"city == 'Denver'\")\n",
    "dfEmp.show()\n",
    "\n",
    "dyf7 = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database = database_name, \n",
    "    table_name = \"employee_department\", \n",
    "    transformation_ctx = \"dyf7\", \n",
    "    additional_options = {\n",
    "        \"transactionId\": txId4\n",
    "    }\n",
    ")\n",
    "df11 = dyf7.toDF()\n",
    "dfDep = df11.select('employee_id','department')\n",
    "\n",
    "dfDep.join(dfEmp,dfDep.employee_id == dfEmp.employee_id).show()\n",
    "\n",
    "glueContext.commit_transaction(txId4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8426a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
